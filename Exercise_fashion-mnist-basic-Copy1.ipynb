{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32102769",
   "metadata": {},
   "source": [
    "# Beyond Hello World, A Computer Vision Example\n",
    "In the previous exercise you saw how to create a neural network that figured out the problem you were trying to solve. This gave an explicit example of learned behavior. Of course, in that instance, it was a bit of overkill because it would have been easier to write the function Y=2x-1 directly, instead of bothering with using Machine Learning to learn the relationship between X and Y for a fixed set of values, and extending that for all values.\n",
    "\n",
    "But what about a scenario where writing rules like that is much more difficult -- for example a computer vision problem? Let's take a look at a scenario where we can recognize different items of clothing, trained from a dataset containing 10 different types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a68913ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print (tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a38fdcf",
   "metadata": {},
   "source": [
    "# Callback to stop training after reaching a certain threshold\n",
    "\n",
    "To stop the training when I reach a desired value?' -- i.e. 95% accuracy might be enough for you, and if you reach that after 3 epochs, why sit around waiting for it to finish a lot more epochs....So how would you fix that? Like any other program...you have callbacks! Let's see them in action..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f4230f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopping once 80% accuracy is reached\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('loss')<0.2):\n",
    "      print(\"\\nReached 80% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "        \n",
    "# We instantiate the class that we just created, we do that with this code. \n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd408bc",
   "metadata": {},
   "source": [
    "The Fashion MNIST data is available directly in the tf.keras datasets API. You load it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "264a446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a809475",
   "metadata": {},
   "source": [
    "Calling load_data on this object will give you two sets of two lists, these will be the training and testing values for the graphics that contain the clothing items and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a31be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb8f7f7",
   "metadata": {},
   "source": [
    "Lets look on how the above values look like. Lets print a training image and training label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a694c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 33]\n",
      "  [ 96]\n",
      "  [175]\n",
      "  [156]\n",
      "  [ 64]\n",
      "  [ 14]\n",
      "  [ 54]\n",
      "  [137]\n",
      "  [204]\n",
      "  [194]\n",
      "  [102]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 73]\n",
      "  [186]\n",
      "  [177]\n",
      "  [183]\n",
      "  [175]\n",
      "  [188]\n",
      "  [232]\n",
      "  [255]\n",
      "  [223]\n",
      "  [219]\n",
      "  [194]\n",
      "  [179]\n",
      "  [186]\n",
      "  [213]\n",
      "  [146]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 35]\n",
      "  [163]\n",
      "  [140]\n",
      "  [150]\n",
      "  [152]\n",
      "  [150]\n",
      "  [146]\n",
      "  [175]\n",
      "  [175]\n",
      "  [173]\n",
      "  [171]\n",
      "  [156]\n",
      "  [152]\n",
      "  [148]\n",
      "  [129]\n",
      "  [156]\n",
      "  [140]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [150]\n",
      "  [142]\n",
      "  [140]\n",
      "  [152]\n",
      "  [160]\n",
      "  [156]\n",
      "  [146]\n",
      "  [142]\n",
      "  [127]\n",
      "  [135]\n",
      "  [133]\n",
      "  [140]\n",
      "  [140]\n",
      "  [137]\n",
      "  [133]\n",
      "  [125]\n",
      "  [169]\n",
      "  [ 75]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 54]\n",
      "  [167]\n",
      "  [146]\n",
      "  [129]\n",
      "  [142]\n",
      "  [137]\n",
      "  [137]\n",
      "  [131]\n",
      "  [148]\n",
      "  [148]\n",
      "  [133]\n",
      "  [131]\n",
      "  [131]\n",
      "  [131]\n",
      "  [125]\n",
      "  [140]\n",
      "  [140]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [110]\n",
      "  [188]\n",
      "  [133]\n",
      "  [146]\n",
      "  [152]\n",
      "  [133]\n",
      "  [125]\n",
      "  [127]\n",
      "  [119]\n",
      "  [129]\n",
      "  [133]\n",
      "  [119]\n",
      "  [140]\n",
      "  [131]\n",
      "  [150]\n",
      "  [ 14]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [221]\n",
      "  [158]\n",
      "  [137]\n",
      "  [135]\n",
      "  [123]\n",
      "  [110]\n",
      "  [110]\n",
      "  [114]\n",
      "  [108]\n",
      "  [112]\n",
      "  [117]\n",
      "  [127]\n",
      "  [142]\n",
      "  [ 77]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  4]\n",
      "  [  0]\n",
      "  [ 25]\n",
      "  [158]\n",
      "  [137]\n",
      "  [125]\n",
      "  [119]\n",
      "  [119]\n",
      "  [110]\n",
      "  [117]\n",
      "  [117]\n",
      "  [110]\n",
      "  [119]\n",
      "  [127]\n",
      "  [144]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [123]\n",
      "  [156]\n",
      "  [129]\n",
      "  [112]\n",
      "  [110]\n",
      "  [102]\n",
      "  [112]\n",
      "  [100]\n",
      "  [121]\n",
      "  [117]\n",
      "  [129]\n",
      "  [114]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [125]\n",
      "  [169]\n",
      "  [127]\n",
      "  [119]\n",
      "  [106]\n",
      "  [108]\n",
      "  [104]\n",
      "  [ 94]\n",
      "  [121]\n",
      "  [114]\n",
      "  [129]\n",
      "  [ 91]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  2]\n",
      "  [  0]\n",
      "  [ 98]\n",
      "  [171]\n",
      "  [129]\n",
      "  [112]\n",
      "  [104]\n",
      "  [114]\n",
      "  [106]\n",
      "  [102]\n",
      "  [112]\n",
      "  [104]\n",
      "  [133]\n",
      "  [ 64]\n",
      "  [  0]\n",
      "  [  4]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  2]\n",
      "  [  0]\n",
      "  [ 66]\n",
      "  [173]\n",
      "  [135]\n",
      "  [129]\n",
      "  [ 98]\n",
      "  [100]\n",
      "  [119]\n",
      "  [102]\n",
      "  [108]\n",
      "  [ 98]\n",
      "  [135]\n",
      "  [ 60]\n",
      "  [  0]\n",
      "  [  4]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  2]\n",
      "  [  0]\n",
      "  [ 56]\n",
      "  [171]\n",
      "  [135]\n",
      "  [127]\n",
      "  [100]\n",
      "  [108]\n",
      "  [117]\n",
      "  [ 85]\n",
      "  [106]\n",
      "  [110]\n",
      "  [135]\n",
      "  [ 66]\n",
      "  [  0]\n",
      "  [  4]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 52]\n",
      "  [150]\n",
      "  [129]\n",
      "  [110]\n",
      "  [100]\n",
      "  [ 91]\n",
      "  [102]\n",
      "  [ 94]\n",
      "  [ 83]\n",
      "  [104]\n",
      "  [123]\n",
      "  [ 66]\n",
      "  [  0]\n",
      "  [  4]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  2]\n",
      "  [  0]\n",
      "  [ 66]\n",
      "  [167]\n",
      "  [140]\n",
      "  [148]\n",
      "  [148]\n",
      "  [127]\n",
      "  [137]\n",
      "  [152]\n",
      "  [146]\n",
      "  [146]\n",
      "  [148]\n",
      "  [ 96]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 45]\n",
      "  [123]\n",
      "  [ 94]\n",
      "  [104]\n",
      "  [ 96]\n",
      "  [119]\n",
      "  [121]\n",
      "  [106]\n",
      "  [ 98]\n",
      "  [112]\n",
      "  [ 87]\n",
      "  [114]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [106]\n",
      "  [ 89]\n",
      "  [ 58]\n",
      "  [ 50]\n",
      "  [ 37]\n",
      "  [ 50]\n",
      "  [ 66]\n",
      "  [ 56]\n",
      "  [ 50]\n",
      "  [ 75]\n",
      "  [ 75]\n",
      "  [137]\n",
      "  [ 22]\n",
      "  [  0]\n",
      "  [  2]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  2]\n",
      "  [  0]\n",
      "  [ 29]\n",
      "  [148]\n",
      "  [114]\n",
      "  [106]\n",
      "  [125]\n",
      "  [ 89]\n",
      "  [100]\n",
      "  [133]\n",
      "  [117]\n",
      "  [131]\n",
      "  [131]\n",
      "  [131]\n",
      "  [125]\n",
      "  [112]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [100]\n",
      "  [106]\n",
      "  [114]\n",
      "  [ 91]\n",
      "  [137]\n",
      "  [ 62]\n",
      "  [102]\n",
      "  [131]\n",
      "  [ 89]\n",
      "  [135]\n",
      "  [112]\n",
      "  [131]\n",
      "  [108]\n",
      "  [135]\n",
      "  [ 37]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [146]\n",
      "  [100]\n",
      "  [108]\n",
      "  [ 98]\n",
      "  [144]\n",
      "  [ 62]\n",
      "  [106]\n",
      "  [131]\n",
      "  [ 87]\n",
      "  [133]\n",
      "  [104]\n",
      "  [160]\n",
      "  [117]\n",
      "  [121]\n",
      "  [ 68]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 33]\n",
      "  [121]\n",
      "  [108]\n",
      "  [ 96]\n",
      "  [100]\n",
      "  [140]\n",
      "  [ 71]\n",
      "  [106]\n",
      "  [127]\n",
      "  [ 85]\n",
      "  [140]\n",
      "  [104]\n",
      "  [150]\n",
      "  [140]\n",
      "  [114]\n",
      "  [ 89]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 62]\n",
      "  [119]\n",
      "  [112]\n",
      "  [102]\n",
      "  [110]\n",
      "  [137]\n",
      "  [ 75]\n",
      "  [106]\n",
      "  [144]\n",
      "  [ 81]\n",
      "  [144]\n",
      "  [108]\n",
      "  [117]\n",
      "  [154]\n",
      "  [117]\n",
      "  [104]\n",
      "  [ 18]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 66]\n",
      "  [121]\n",
      "  [102]\n",
      "  [112]\n",
      "  [117]\n",
      "  [131]\n",
      "  [ 73]\n",
      "  [104]\n",
      "  [156]\n",
      "  [ 77]\n",
      "  [137]\n",
      "  [135]\n",
      "  [ 83]\n",
      "  [179]\n",
      "  [129]\n",
      "  [121]\n",
      "  [ 35]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 85]\n",
      "  [127]\n",
      "  [ 81]\n",
      "  [125]\n",
      "  [133]\n",
      "  [119]\n",
      "  [ 79]\n",
      "  [100]\n",
      "  [169]\n",
      "  [ 83]\n",
      "  [129]\n",
      "  [175]\n",
      "  [ 60]\n",
      "  [163]\n",
      "  [135]\n",
      "  [146]\n",
      "  [ 39]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [106]\n",
      "  [129]\n",
      "  [ 62]\n",
      "  [140]\n",
      "  [144]\n",
      "  [108]\n",
      "  [ 85]\n",
      "  [ 83]\n",
      "  [158]\n",
      "  [ 85]\n",
      "  [129]\n",
      "  [175]\n",
      "  [ 48]\n",
      "  [146]\n",
      "  [133]\n",
      "  [135]\n",
      "  [ 64]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [117]\n",
      "  [119]\n",
      "  [ 79]\n",
      "  [140]\n",
      "  [152]\n",
      "  [102]\n",
      "  [ 89]\n",
      "  [110]\n",
      "  [137]\n",
      "  [ 96]\n",
      "  [150]\n",
      "  [196]\n",
      "  [ 83]\n",
      "  [144]\n",
      "  [135]\n",
      "  [133]\n",
      "  [ 77]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [154]\n",
      "  [121]\n",
      "  [ 87]\n",
      "  [140]\n",
      "  [154]\n",
      "  [112]\n",
      "  [ 94]\n",
      "  [ 52]\n",
      "  [142]\n",
      "  [100]\n",
      "  [ 83]\n",
      "  [152]\n",
      "  [ 85]\n",
      "  [160]\n",
      "  [133]\n",
      "  [100]\n",
      "  [ 12]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  4]\n",
      "  [  0]\n",
      "  [  2]\n",
      "  [  0]\n",
      "  [ 35]\n",
      "  [  4]\n",
      "  [ 33]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]]\n",
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAASyklEQVR4nO3da4xd1XUH8P//PmY8D4/t8SvGGIeHgzFIQDRy3FIVKpoUUBRIpVRx05RUqI6qEAUpqoroh9B+IlUJyocqklNQTJqAIgHClazW1EpF0lDCAA7YMQXi+D32YI+N5z33sfphjsMAc9a+3Pd4/3/SaGbumnPPumdm3XPnrrP3pplBRC5+mVYnICLNoWIXiYSKXSQSKnaRSKjYRSKRa+bOOthpi9DTzF22BXYtcuMzfVk3nusruPFCKX373Ij/fJ4dm3Lj5e5ONz6z1A2jv3c8NVYo+497/FyXG8+fTL/vWE1hHDM2zfliNRU7ydsAfBdAFsC/mtlD3s8vQg8+xVtr2eWClLlqoxs/8el+N77s9hNufOhsX2ps1ZN+wSz+2dtufOqTl7vx3/6p/2TypS0vpMZOTafnDQAvPH29G1/77V+48Ri9aHtSY1W/jCeZBfAvAG4HsAnAVpKbqr0/EWmsWv5n3wzgbTM7aGYzAJ4EcGd90hKRequl2NcCODrn+2PJbe9DchvJQZKDBUzXsDsRqUUtxT7fmwAfuvbWzLab2YCZDeThv9kjIo1TS7EfA7BuzveXAvDfSRKRlqml2F8CsIHk5SQ7AHwRwM76pCUi9VZ1683MiiTvBfCfmG29PWZm++uWWZs5/+dbUmNr/8ZvX52dnnDj6/Pn/H1P+336Gy89lhr7+sP/5W570yL/+f6pMb89Nl7ucOM/e/fq1NiRsWXuths/+6Ybv/kvz7rxR17649TYhq+87G57Maqpz25muwDsqlMuItJAulxWJBIqdpFIqNhFIqFiF4mEil0kEip2kUiwmbPL9rHf2nWIa+b6a9z48X9Ij40O9/r33V1048z4vwMrzzs8+b14Mf05+7JLzrjbhhTL/vmgZH5uI+fT5y8olfz7LjuPCwA44vf4c2vSr2+Yede/dPsT215y4+3qRduD8zYy7y9FZ3aRSKjYRSKhYheJhIpdJBIqdpFIqNhFItHUqaTb2Zt/6w8jLZ/2pz32hFprnZ3+VNHFor/vgtOiOnxkhbtt5rz/J1BeVHbjDLUFO/zt/Z37942cf1xLR7tTYyuv8VuS7/5F+pBmAFjyb//rxtuRzuwikVCxi0RCxS4SCRW7SCRU7CKRULGLRELFLhIJ9dkT6x/3e9nvfv18auzsmcXutjbs9/AnegO/hsBQTw9nAn3wFTP+9qEdnM/720817nySCTy2Ul8pNfbO8aXutp9YgH30EJ3ZRSKhYheJhIpdJBIqdpFIqNhFIqFiF4mEil0kEuqzJ/K7B934xJbfT41t/pM33G1/+eoGN87AuOxMt98LL4+kT4sc6kXbaX865ux0oJfdFZgG23lsuVH/XFNY7k/BXQ6cq7wpvK++74i7bXqHfuGqqdhJHgIwitljUzSzgXokJSL1V48z+x+Z2ek63I+INJD+ZxeJRK3FbgB2k3yZ5Lb5foDkNpKDJAcLmK5xdyJSrVpfxt9kZidIrgLwHMk3zOz5uT9gZtsBbAdm13qrcX8iUqWazuxmdiL5PAzgGQCb65GUiNRf1cVOsofk4gtfA/gMgH31SkxE6quWl/GrATxD8sL9/NjM/qMuWbWhy/7xF6mxu7502N32V6vXuvGpM11uvDThj7XPTaQ/Z+fGgiPSXV6fHABy4/75wpy/sHI+cH3BmP+4y31+H37l7vR5BEqna1vKeiGqutjN7CCA6+uYi4g0kFpvIpFQsYtEQsUuEgkVu0gkVOwikdAQ1wTz/lBPK6QPM/3h7Tf7d/7tajJ6T9ZprQEAnfGYoSGo2cnAENjAStWh+884Q2St1lNNYPulj79Q4w4uLjqzi0RCxS4SCRW7SCRU7CKRULGLRELFLhIJFbtIJNRnT3h99JDiwUN+/Le/58Y71o/72091u/GsN4y17G6KbGimsIzfh8/5qWNqeXofPhOarzlwKuo85i8XLe+nM7tIJFTsIpFQsYtEQsUuEgkVu0gkVOwikVCxi0RCffYmsIw/5ntJ76QbP1P2++ylzvT7z4/6ffJyoFWdCfThM9VfnuCOw69E13Bt02THRmd2kUio2EUioWIXiYSKXSQSKnaRSKjYRSKhYheJhPrslco4E6iX/YZx95D/nJq9NjDoPPCUnHXmZoff4ke5IzCv/JTfyy6lr4oMAMg524d6+DP9/nHpPV59o76WdQIWquCZneRjJIdJ7ptzWz/J50i+lXxe1tg0RaRWlbyM/wGA2z5w2/0A9pjZBgB7ku9FpI0Fi93Mngcw8oGb7wSwI/l6B4C76puWiNRbtW/QrTazIQBIPq9K+0GS20gOkhwsIDThmYg0SsPfjTez7WY2YGYDeXQ2encikqLaYj9Fcg0AJJ+H65eSiDRCtcW+E8Ddydd3A3i2PumISKME++wknwBwC4AVJI8B+BaAhwD8hOQ9AI4A+EIjk1zo+g4F+sH0e93lDr/fPLM0PdZz1H8+zxT9Pvp0v59bxzl/exbTY9lAKzs0D0Cm4G8v7xcsdjPbmhK6tc65iEgD6XJZkUio2EUioWIXiYSKXSQSKnaRSGiIaxPkx/3W2ZTVOCWyc/cWeDovBS5qZGD0bedZvz02tSL9sRV6/PsOKXVqKumPQmd2kUio2EUioWIXiYSKXSQSKnaRSKjYRSKhYheJhPrslQpMF+3JFPxm9fCZPn/7Gf85ueNc9c/Znef8eKHg97KLXf72XcPpffjJlf5958ac6bsBuBcYyIfozC4SCRW7SCRU7CKRULGLRELFLhIJFbtIJFTsIpFQn71SNSzZPL3UP8xLl5x14yMT/vbT/elzMocW3OJpf+nicrffy872+fNBl2dCvXJHYCrp0cv89aK94fIX45LMITqzi0RCxS4SCRW7SCRU7CKRULGLRELFLhIJFbtIJNRnr1QN49m7T/rd7lMHlrvxvuOBMeXd+dRYbsrdFJOrAssiB/rkHUe63XjWeeiFxe6m6Drp5zZxiR+X9wue2Uk+RnKY5L45tz1I8jjJvcnHHY1NU0RqVcnL+B8AuG2e2x8xsxuSj131TUtE6i1Y7Gb2PICRJuQiIg1Uyxt095J8LXmZvyzth0huIzlIcrAQvFJbRBql2mL/HoArAdwAYAjAw2k/aGbbzWzAzAbyCKwiKCINU1Wxm9kpMyuZWRnA9wFsrm9aIlJvVRU7yTVzvv08gH1pPysi7SHYZyf5BIBbAKwgeQzAtwDcQvIGAAbgEICvNi7Fhe/4zX4vuveQv/2SQwU3nptMvwYgd85/n6S41P/Xaqo/vYcPhNeez06n5za21h9LH3J2lb/v3Pp1qbHi4aP+nXvzFwA1XXfRKsFiN7Ot89z8aANyEZEG0uWyIpFQsYtEQsUuEgkVu0gkVOwikdAQ1wtqaLVkr77K3XRyoz/OtHTIb3/NLPXbX9P96bkvPuhPt1z05lsGML7ebzHl3/X/hAqLvfNJbUNUs2P+uergX6W33i57MNB6W4CttRCd2UUioWIXiYSKXSQSKnaRSKjYRSKhYheJhIpdJBLqs19QQ1/16OdWufGuN/ztS4v8fnPHeX/7icvSh3ouPu4PAx3ZGPgT8DdHd2Ca63PXpT+2RcOhpaj930nHOf9cNXlJMTXGG691t7VX97vxhUhndpFIqNhFIqFiF4mEil0kEip2kUio2EUioWIXiYT67HUwfq0/XXPPfn+8umX8XnUptJBOh9cM95/PLTCMP4Rl/xoBltMfWyawGljX2jE3Xhztc+O58+kPbvSqXnfb3lfd8IKkM7tIJFTsIpFQsYtEQsUuEgkVu0gkVOwikVCxi0RCffYKZa7bmBrLnvSXHg71yfPjfrwc+i0V03vZxa7ans/p3DcAMDDe3dxrAPwm/9Skf1zLK9PHqwNA58n0Azex0t+334VfmIJ/CSTXkfwpyQMk95P8RnJ7P8nnSL6VfF7W+HRFpFqVPO0XAXzTzK4BsAXA10huAnA/gD1mtgHAnuR7EWlTwWI3syEzeyX5ehTAAQBrAdwJYEfyYzsA3NWgHEWkDj7SP3QkPw7gRgAvAlhtZkPA7BMCgHknYiO5jeQgycECAhdDi0jDVFzsJHsBPAXgPjMLTIH4HjPbbmYDZjaQR2hEh4g0SkXFTjKP2UL/kZk9ndx8iuSaJL4GwHBjUhSRegi23kgSwKMADpjZd+aEdgK4G8BDyednG5Jhmxi/Mn04JQMrD1vgKJf8DlN4iKszjDTYtgvd9VK/vZUp+stJI5d+cELDa3OH/eWm7YoJP/5O+oOfWRLY95qPufHi0En/DtpQJX8KNwH4MoDXSe5NbnsAs0X+E5L3ADgC4AsNyVBE6iJY7Gb2cwBpp45b65uOiDSKLpcViYSKXSQSKnaRSKjYRSKhYheJhIa4VqicS+9lmz8KFNlJP17qCuw7H5iueSY9gdAQVASuEejomXHjwT77TPr5xFtSGQCWv+I34pdvOePG3z6VfmDLgR5/eVVgEOcC7LPrzC4SCRW7SCRU7CKRULGLRELFLhIJFbtIJFTsIpFQn71Ck8vTnxfLHX6zuusd/77PbvK3Ly/y47nR9NxCY+UzfqsbS3r9iwRKHT3+/U+l57Zuk9+rtl3zznT2O0Oji9142ZnG2paW/H3na1zLug3pzC4SCRW7SCRU7CKRULGLRELFLhIJFbtIJFTsIpFQn71CUyucQeuZQJ/9jN/TPd0XGFTuzL0OALmT6T3hUuAagM6zfnx0wp+7vbuBp4uO0YIbHzvX7cbpzKdvE34ffXydf/1A96Abbks6s4tEQsUuEgkVu0gkVOwikVCxi0RCxS4SCRW7SCQqWZ99HYDHAXwMQBnAdjP7LskHAfw1gAujtR8ws12NSrTVij3p/ejspD9x/NSy0Nhof1B5dlFgjfRC+qB1b757AJha4YYxdcaf1L6jJzBp/oqp1NCmZf549l9uWOPGrez34b3rH7wePADMLPbPg36Hvz1VclFNEcA3zewVkosBvEzyuST2iJn9c+PSE5F6qWR99iEAQ8nXoyQPAFjb6MREpL4+0v/sJD8O4EYALyY33UvyNZKPkZx3vRyS20gOkhwsYLq2bEWkahUXO8leAE8BuM/MzgP4HoArAdyA2TP/w/NtZ2bbzWzAzAby6Kw9YxGpSkXFTjKP2UL/kZk9DQBmdsrMSmZWBvB9AJsbl6aI1CpY7CQJ4FEAB8zsO3Nun/tW6ecB7Kt/eiJSL5W8G38TgC8DeJ3k3uS2BwBsJXkDZhf9PQTgqw3Ir23YFRPpscN+I6bojxINytAfhuot+ZxN73wBAC75H/99lINb/RZVOfAXtOy/0x/87sxGd9slgVNR9xJ/muvJid7UWM/hwHLQ/37AjfuDlttTJe/G/xzAfL/xi7anLnIx0hV0IpFQsYtEQsUuEgkVu0gkVOwikVCxi0SCZoFpjOuoj/32Kd7atP3VE/Ppw0itMONvnAkMcS37XdvM9de4cfv1b1JjvPoKf9f73nDjsrC8aHtw3kbmvThCZ3aRSKjYRSKhYheJhIpdJBIqdpFIqNhFIqFiF4lEU/vsJN8BcHjOTSsAnG5aAh9Nu+bWrnkByq1a9cxtvZmtnC/Q1GL/0M7JQTMbaFkCjnbNrV3zApRbtZqVm17Gi0RCxS4SiVYX+/YW79/Trrm1a16AcqtWU3Jr6f/sItI8rT6zi0iTqNhFItGSYid5G8n/I/k2yftbkUMakodIvk5yL8nBFufyGMlhkvvm3NZP8jmSbyWf511jr0W5PUjyeHLs9pK8o0W5rSP5U5IHSO4n+Y3k9pYeOyevphy3pv/PTjIL4E0AnwZwDMBLALaa2a+bmkgKkocADJhZyy/AIPmHAMYAPG5m1yW3/ROAETN7KHmiXGZmf9cmuT0IYKzVy3gnqxWtmbvMOIC7AHwFLTx2Tl5/hiYct1ac2TcDeNvMDprZDIAnAdzZgjzanpk9D2DkAzffCWBH8vUOzP6xNF1Kbm3BzIbM7JXk61EAF5YZb+mxc/JqilYU+1oAR+d8fwzttd67AdhN8mWS21qdzDxWm9kQMPvHA2BVi/P5oOAy3s30gWXG2+bYVbP8ea1aUezzzY/VTv2/m8zskwBuB/C15OWqVKaiZbybZZ5lxttCtcuf16oVxX4MwLo5318K4EQL8piXmZ1IPg8DeAbttxT1qQsr6Cafh1ucz++00zLe8y0zjjY4dq1c/rwVxf4SgA0kLyfZAeCLAHa2II8PIdmTvHECkj0APoP2W4p6J4C7k6/vBvBsC3N5n3ZZxjttmXG0+Ni1fPlzM2v6B4A7MPuO/G8A/H0rckjJ6woAv0o+9rc6NwBPYPZlXQGzr4juAbAcwB4AbyWf+9sotx8CeB3Aa5gtrDUtyu0PMPuv4WsA9iYfd7T62Dl5NeW46XJZkUjoCjqRSKjYRSKhYheJhIpdJBIqdpFIqNhFIqFiF4nE/wMwBJKaFihyhAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=200)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(training_images[3])\n",
    "print (training_images[3])\n",
    "print (training_labels[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89dde9e",
   "metadata": {},
   "source": [
    "# Normalize the data\n",
    "All values in the above image array is in 0 to 255 range. Normalize them by bringing them in the range of 0 to 1.\n",
    "fortunately in Python it's easy to normalize a list like this without looping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfc9d449",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c721c91",
   "metadata": {},
   "source": [
    "# Design the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8e0db8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "                        tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "                        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "                        tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10,activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9efd5d9",
   "metadata": {},
   "source": [
    "**Sequential** : This defines the sequence of layers in the nueral network. \n",
    "\n",
    "**Flatten** : This converts the input shape into linear. Converts our square image into 1 dimension set.\n",
    "\n",
    "**Dense** : Adds layers of nuerons\n",
    "\n",
    "Each layer needs activation function to tell them what to do.  Examples are:\n",
    "\n",
    "**Relu** : means if X>0, return X, else return 0, --> so what it does is it passes values 0 or greater to the next layer in the network.\n",
    "\n",
    "**Softmax** : Takes a set of values and effective picks the bigger one.Eg: if output of last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it saves you from fishing through it looking for the biggest value, and turns it into [0,0,0,0,1,0,0,0,0] -- The goal is to save a lot of coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd980bc",
   "metadata": {},
   "source": [
    "# Compile the model\n",
    "Now to build the model once you defined the model. This is done by compiling it with an optimizer and a loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a4d4fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.optimizers.Adam(),\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19877880",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "Training is done by model.fit (x,y,epochs = 10)  OR\n",
    "model.fit (training_images,training_labels, epochs = 10)\n",
    "\n",
    "Asking it to fit your training data to your training labels -- i.e. have it figure out the relationship between the training data and its actual labels, so in future if you have data that looks like the training data, then it can make a prediction for what that data would look like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "070840a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.9110 - accuracy: 0.6683\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.5742 - accuracy: 0.7876\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.5168 - accuracy: 0.8118\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.4803 - accuracy: 0.8279\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.4558 - accuracy: 0.8380\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.4367 - accuracy: 0.8447\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.4235 - accuracy: 0.8497\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.4126 - accuracy: 0.8529\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.4007 - accuracy: 0.8578\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.3932 - accuracy: 0.8603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x206dc827c10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In model.fit, I used the callbacks parameter and pass it this instance of the class.\n",
    "model.fit(training_images, training_labels, epochs=10,  callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b4d036",
   "metadata": {},
   "source": [
    "# Evaluate the model\n",
    "Once it's done training -- you should see an accuracy value at the end of the final epoch. It might look something like 0.9098. This tells you that your neural network is about 91% accurate in classifying the training data. I.E., it figured out a pattern match between the image and the labels that worked 91% of the time. Not great, but not bad considering it was only trained for 5 epochs and done quite quickly.\n",
    "\n",
    "But how would it work with unseen data? That's why we have the test images. We can call model.evaluate, and pass in the two sets, and it will report back the loss for each. Let's give it a try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fcb0824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 821us/step - loss: 0.3219 - accuracy: 0.8848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32189545035362244, 0.8848000168800354]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e8dee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36424eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2db1a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55f4d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
