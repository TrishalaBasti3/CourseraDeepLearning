{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d49080b9",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "In the course you learned how to do classificaiton using Fashion MNIST, a data set containing items of clothing. There's another, similar dataset called MNIST which has items of handwriting -- the digits 0 through 9.\n",
    "\n",
    "Write an MNIST classifier that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy.\n",
    "\n",
    "**Some notes:**\n",
    "\n",
    "\n",
    "It should succeed in less than 10 epochs, so it is okay to change epochs= to 10, but nothing larger\n",
    "When it reaches 99% or greater it should print out the string \"Reached 99% accuracy so cancelling training!\"\n",
    "If you add any additional variables, make sure you use the same names as the ones used in the class\n",
    "I've started the code for you below -- how would you finish it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1067b7",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fbda65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "from os import path, getcwd, chdir\n",
    "path = f\"{getcwd()}\\\\mnist.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f592a2",
   "metadata": {},
   "source": [
    "# Define the accuray threshold for epochs to stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb41ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('loss')<0.03):\n",
    "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f075dcda",
   "metadata": {},
   "source": [
    "# Create a function to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27927db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mnist():\n",
    "    callbacks = myCallback()\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data(path=path)\n",
    "    #normalize\n",
    "    x_train = x_train/255.0\n",
    "    x_test = x_test/255.0\n",
    "    # Design the model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape = (28,28)),\n",
    "       # tf.keras.layers.Dense(32, activation = tf.nn.relu),\n",
    "       # tf.keras.layers.Dense(64, activation = tf.nn.relu),\n",
    "       # tf.keras.layers.Dense(128, activation = tf.nn.relu),\n",
    "       # tf.keras.layers.Dense(256, activation = tf.nn.relu),\n",
    "        tf.keras.layers.Dense(512, activation = tf.nn.relu),\n",
    "        tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
    "    ])\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(x_train, y_train, steps_per_epoch=20, epochs=40, callbacks=[callbacks])\n",
    "    \n",
    "    # return accuracy\n",
    "    return history.epoch, history.history['accuracy'][-1]\n",
    "    #return history.epoch, history.history['acc'][-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a325bf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.9660 - accuracy: 0.7565\n",
      "Epoch 2/40\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3431 - accuracy: 0.9016\n",
      "Epoch 3/40\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2652 - accuracy: 0.9250\n",
      "Epoch 4/40\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2256 - accuracy: 0.9367\n",
      "Epoch 5/40\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.1970 - accuracy: 0.9446\n",
      "Epoch 6/40\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.1748 - accuracy: 0.9510\n",
      "Epoch 7/40\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.1555 - accuracy: 0.9572\n",
      "Epoch 8/40\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.1398 - accuracy: 0.9617\n",
      "Epoch 9/40\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.1259 - accuracy: 0.9658\n",
      "Epoch 10/40\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.1148 - accuracy: 0.9688\n",
      "Epoch 11/40\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.1044 - accuracy: 0.9719\n",
      "Epoch 12/40\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.0957 - accuracy: 0.9740\n",
      "Epoch 13/40\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0890 - accuracy: 0.9758\n",
      "Epoch 14/40\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0827 - accuracy: 0.9780\n",
      "Epoch 15/40\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.0759 - accuracy: 0.9799\n",
      "Epoch 16/40\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.0701 - accuracy: 0.9814\n",
      "Epoch 17/40\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0652 - accuracy: 0.9829\n",
      "Epoch 18/40\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.0605 - accuracy: 0.9845\n",
      "Epoch 19/40\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.0567 - accuracy: 0.9855\n",
      "Epoch 20/40\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0533 - accuracy: 0.9864\n",
      "Epoch 21/40\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.0498 - accuracy: 0.9874\n",
      "Epoch 22/40\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.0472 - accuracy: 0.9882\n",
      "Epoch 23/40\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0439 - accuracy: 0.9889\n",
      "Epoch 24/40\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.0412 - accuracy: 0.9900\n",
      "Epoch 25/40\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.0389 - accuracy: 0.9905\n",
      "Epoch 26/40\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0366 - accuracy: 0.9915\n",
      "Epoch 27/40\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0346 - accuracy: 0.9920\n",
      "Epoch 28/40\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.0328 - accuracy: 0.9925\n",
      "Epoch 29/40\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0305 - accuracy: 0.9933\n",
      "Epoch 30/40\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0287 - accuracy: 0.9939\n",
      "\n",
      "Reached 99% accuracy so cancelling training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29],\n",
       " 0.9938833117485046)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the function\n",
    "train_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e93d54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# class myCallback(tf.keras.callbacks.Callback):\n",
    "#   def on_epoch_end(self, epoch, logs={}):\n",
    "#     if(logs.get('accuracy')>0.99):\n",
    "#       print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "#       self.model.stop_training = True\n",
    "\n",
    "# mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "# x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# callbacks = myCallback()\n",
    "\n",
    "# model = tf.keras.models.Sequential([\n",
    "#   tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "#   tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "#   tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "# ])\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
